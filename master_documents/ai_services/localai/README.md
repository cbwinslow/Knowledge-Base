# LocalAI

LocalAI is an API to run LLMs locally, written in Go with a focus on performance and versatility.

## Setup

To set up LocalAI, run:
```bash
./setup_localai.sh
```

## Access

Once running, LocalAI will be accessible at http://localhost:8080

## Configuration

- `docker-compose.yml` - Docker Compose configuration
- `config/application.yaml` - LocalAI configuration
- `models/` - Directory for model files

## Usage

Refer to the [LocalAI documentation](https://localai.io) for detailed usage instructions.
